{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all Heatmaps (Occlusion of GradCam) for a given Version\n",
    "\n",
    "Generates a PDF with all heatmaps for a given version.\n",
    "\n",
    "- Choose heatmap type (Occlusion or GradCam)\n",
    "- Choose if heatmaps should be genereated or loaded\n",
    "- Choose if pictures (mean over all axis, highest heatmap value slice, original image) should be generated or loaded\n",
    "- Choose if all patients should be used or only wrongly classified ones  \n",
    "  \n",
    "\n",
    "  \n",
    "- Define if only the predicted class should be visualized (default: predicted class)\n",
    "- Define if only last gradcam layer should be visualized (default: last layer)\n",
    "\n",
    "## Load Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm\n",
    "#pip install seaborn\n",
    "#pip install fpdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF  Version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc as gci\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fpdf import FPDF\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/schnemau/xAI_stroke_3d\n",
      "/tf/notebooks/schnemau/xAI_stroke_3d\n"
     ]
    }
   ],
   "source": [
    "# check and set path before loading modules\n",
    "print(os.getcwd())\n",
    "DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/\"\n",
    "if os.getcwd() != DIR:\n",
    "    os.chdir(DIR)\n",
    "    \n",
    "import functions_metrics as fm\n",
    "import functions_read_data as rdat\n",
    "import functions_model_definition as md\n",
    "import functions_gradcam as gc\n",
    "import functions_occlusion as oc\n",
    "import functions_plot_heatmap as phm\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Utils_maurice as utils\n",
    "\n",
    "#ontram functions\n",
    "from k_ontram_functions.ontram import ontram\n",
    "from k_ontram_functions.ontram_loss import ontram_loss\n",
    "from k_ontram_functions.ontram_metrics import ontram_acc, ontram_auc\n",
    "from k_ontram_functions.ontram_predict import predict_ontram, get_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path + output path:\n",
    "DATA_DIR = DIR + \"data/\"\n",
    "version = \"10Fold_CIBLSX\" # one of:\n",
    "# 10Fold_sigmoid_V0, 10Fold_sigmoid_V1, 10Fold_sigmoid_V2, 10Fold_sigmoid_V2f, 10Fold_sigmoid_V3\n",
    "# 10Fold_softmax_V0, 10Fold_softmax_V1, andrea\n",
    "generate_heatmap_and_save = True # should the heatmap be generated and saved (else loaded)\n",
    "generate_pictures = True # should the pictures be generated (else loaded)\n",
    "only_wrong_out = False # should the generated pdf only contain the wrong predictions (else all)\n",
    "\n",
    "hm_type = \"oc\" # gc or oc => gradcam or occlusion\n",
    "\n",
    "pred_hm_only = True # if true heatmap of prediction will be generated else positive and negative heatmaps are shown\n",
    "last_layer_only = True # Default = True, only last layer will be used for gradcam else once last and once all layers \n",
    "\n",
    "# Define Model Version\n",
    "model_version = 1\n",
    "\n",
    "# define paths\n",
    "WEIGHT_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/weights/10Fold_CIBLSX/\"\n",
    "DATA_OUTPUT_DIR = '/tf/notebooks/schnemau/xAI_stroke_3d/pictures/10Fold_CIBLSX/'\n",
    "PIC_OUTPUT_DIR = '/tf/notebooks/schnemau/xAI_stroke_3d/pictures/10Fold_CIBLSX/'\n",
    "pic_save_name = '10Fold_V0_M1_oc_predcl_tabular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tabular data\n",
    "tabular_df = rdat.split_data_tabular_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_setup(DATA_DIR, version, model_version):\n",
    "    # DATA_DIR: directory where data is stored\n",
    "    # version: which data to use (e.g. 10Fold_sigmoid_V1)\n",
    "    # model_version: which model version to use\n",
    "\n",
    "    id_tab = pd.read_csv(DATA_DIR + \"10Fold_ids_V0.csv\", sep=\",\")\n",
    "    num_models = 5\n",
    "    pat = id_tab[\"p_id\"].to_numpy()\n",
    "    X_in = np.load(DATA_DIR + \"prepocessed_dicom_3d.npy\")\n",
    "    path_results = DATA_DIR + \"all_tab_results_\" + version + \"_M\" + str(model_version) + \".csv\" # 10 Fold\n",
    "    all_results = pd.read_csv(path_results, sep=\",\")\n",
    "    all_results = all_results.sort_values(\"p_idx\")\n",
    "    return X_in, pat, id_tab, all_results, num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>mrs3</th>\n",
       "      <th>age</th>\n",
       "      <th>sexm</th>\n",
       "      <th>nihss_baseline</th>\n",
       "      <th>mrs_before</th>\n",
       "      <th>stroke_beforey</th>\n",
       "      <th>tia_beforey</th>\n",
       "      <th>ich_beforey</th>\n",
       "      <th>rf_hypertoniay</th>\n",
       "      <th>rf_diabetesy</th>\n",
       "      <th>rf_hypercholesterolemiay</th>\n",
       "      <th>rf_smokery</th>\n",
       "      <th>rf_atrial_fibrillationy</th>\n",
       "      <th>rf_chdy</th>\n",
       "      <th>eventtia</th>\n",
       "      <th>iaty</th>\n",
       "      <th>ivty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>85,6</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>66,7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>29,2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>89,2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>540</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     p_id  mrs3   age  sexm  nihss_baseline  mrs_before  stroke_beforey  \\\n",
       "0     101     1  85,6     0             9.0         3.0             0.0   \n",
       "1     102     1  66,7     1             NaN         1.0             0.0   \n",
       "2     103     0  29,2     0             0.0         0.0             0.0   \n",
       "3     104     0    83     1             0.0         0.0             0.0   \n",
       "4     105     6  89,2     0             0.0         0.0             0.0   \n",
       "..    ...   ...   ...   ...             ...         ...             ...   \n",
       "513   540     2    80     0             7.0         0.0             0.0   \n",
       "514   541     0    19     1            10.0         0.0             0.0   \n",
       "515   542     1    68     1             3.0         0.0             0.0   \n",
       "516   543     4    74     0             4.0         0.0             NaN   \n",
       "517   544     1    44     1             4.0         0.0             0.0   \n",
       "\n",
       "     tia_beforey  ich_beforey  rf_hypertoniay  rf_diabetesy  \\\n",
       "0            0.0          0.0             1.0           0.0   \n",
       "1            0.0          0.0             0.0           0.0   \n",
       "2            0.0          0.0             0.0           0.0   \n",
       "3            0.0          0.0             0.0           1.0   \n",
       "4            0.0          0.0             1.0           0.0   \n",
       "..           ...          ...             ...           ...   \n",
       "513          0.0          0.0             1.0           0.0   \n",
       "514          0.0          0.0             0.0           0.0   \n",
       "515          0.0          0.0             1.0           1.0   \n",
       "516          NaN          NaN             NaN           NaN   \n",
       "517          0.0          0.0             0.0           0.0   \n",
       "\n",
       "     rf_hypercholesterolemiay  rf_smokery  rf_atrial_fibrillationy  rf_chdy  \\\n",
       "0                         0.0         0.0                      0.0      1.0   \n",
       "1                         0.0         1.0                      0.0      0.0   \n",
       "2                         0.0         0.0                      0.0      0.0   \n",
       "3                         1.0         0.0                      0.0      0.0   \n",
       "4                         1.0         0.0                      0.0      0.0   \n",
       "..                        ...         ...                      ...      ...   \n",
       "513                       1.0         0.0                      0.0      0.0   \n",
       "514                       0.0         0.0                      0.0      0.0   \n",
       "515                       0.0         0.0                      0.0      0.0   \n",
       "516                       NaN         NaN                      NaN      NaN   \n",
       "517                       0.0         0.0                      0.0      0.0   \n",
       "\n",
       "     eventtia  iaty ivty  \n",
       "0           0   NaN  NaN  \n",
       "1           0   NaN  NaN  \n",
       "2           0   NaN  NaN  \n",
       "3           0   NaN  NaN  \n",
       "4           0   NaN  NaN  \n",
       "..        ...   ...  ...  \n",
       "513         1   0.0    0  \n",
       "514         1   1.0    1  \n",
       "515         1   0.0    0  \n",
       "516         1   0.0    0  \n",
       "517         1   0.0    1  \n",
       "\n",
       "[518 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load images and ids\n",
    "(X_in, pat, id_tab, all_results, num_models) = version_setup(\n",
    "    DATA_DIR = DATA_DIR, version = version, model_version = model_version)\n",
    "\n",
    "## load patient data\n",
    "PAT_CSV_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/data/baseline_data_zurich_prepared0.csv\" \n",
    "pat_dat = pd.read_csv(PAT_CSV_DIR, sep=\";\")\n",
    "pat_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_valid, X_test),(X_tab_train, X_tab_valid, X_tab_test), (y_train, y_valid, y_test) = rdat.split_data_tabular(id_tab, X_in, 1)\n",
    "\n",
    "input_dim = (128, 128, 28, 1)\n",
    "output_dim = 1\n",
    "batch_size = 6\n",
    "C = 2 \n",
    "\n",
    "mbl = utils.img_model_linear_final(input_dim, output_dim)\n",
    "mls = utils.mod_linear_shift(X_tab_train.shape[1])\n",
    "model_3d = ontram(mbl, mls)             \n",
    "\n",
    "model_3d.compile(optimizer=keras.optimizers.Adam(learning_rate=5*1e-5),\n",
    "                                loss=ontram_loss(C, batch_size),\n",
    "                                metrics=[ontram_acc(C, batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_generate_model_name(model_version, path):\n",
    "    def generate_model_name(which_split, model_nr):\n",
    "\n",
    "        return (path + \"3d_cnn_binary_model_split\" + \"CIB_LSX\" + str(which_split) + \n",
    "                \"_normalized_avg_layer_paper_model_\" + \"linear\" + \n",
    "                \"_activation_\"  + str(model_version) + \"_\" + str(model_nr) + \".h5\")\n",
    "        \n",
    "            \n",
    "    return generate_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Name\n",
    "generate_model_name = set_generate_model_name(\n",
    "    model_version = 1, \n",
    "    path = WEIGHT_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot GradCams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Heatmap and Heatmap Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all patients\n",
    "p_ids = all_results[\"p_id\"].to_numpy()\n",
    "\n",
    "(res_table, res_images, res_model_names) = gc.get_img_and_models(\n",
    "    p_ids, results = all_results, pats = pat, imgs = X_in,\n",
    "    gen_model_name = generate_model_name,\n",
    "    num_models = num_models) # 10 Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv3d', 'conv3d_1', 'conv3d_2', 'conv3d_3']\n"
     ]
    }
   ],
   "source": [
    "vis_layers = [i.name for i in model_3d.layers[1:-6]]\n",
    "vis_layers = [vis_layer for vis_layer in vis_layers if vis_layer.startswith(\"conv\")]\n",
    "print(vis_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all patients and generate heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of occlusions per model:  1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/407 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# lc = last conv layer\n",
    "# ac = average over all conv layer\n",
    "\n",
    "if pred_hm_only:\n",
    "    gcpp_hm = \"last\" # gc\n",
    "    both_directions = False # oc\n",
    "    cmap = \"jet\" # both\n",
    "    hm_positive=True # both\n",
    "else:\n",
    "    gcpp_hm = \"none\" # gc\n",
    "    both_directions = True # oc\n",
    "    cmap = \"bwr\" # both\n",
    "    hm_positive=False # both\n",
    "    \n",
    "if \"sigmoid\" in version or \"andrea_split\" in version:\n",
    "    pred_idx = 0\n",
    "elif \"softmax\" in version:\n",
    "    pred_idx = 1\n",
    "    \n",
    "occ_size = (20, 20, 16)\n",
    "occ_stride = 6\n",
    "num_occlusion =  int(np.prod(((np.array(res_images.shape[1:4]) - occ_size) / occ_stride) + 1))\n",
    "print('number of occlusions per model: ', num_occlusion)\n",
    "\n",
    "if generate_heatmap_and_save:\n",
    "\n",
    "    heatmaps_lc = []\n",
    "    max_hm_slices_lc = []\n",
    "    hm_mean_stds_lc = []\n",
    "\n",
    "    heatmaps_ac = []\n",
    "    max_hm_slices_ac = []\n",
    "    hm_mean_stds_ac = []\n",
    "\n",
    "    resized_imgs = []\n",
    "\n",
    "    model_mode = \"mean\"\n",
    "\n",
    "    for i in tqdm(range(len(res_table))):  \n",
    "        \n",
    "        # define if and how heatmap should be inverted\n",
    "        if pred_hm_only and hm_type == \"gc\":\n",
    "            invert_hm = \"all\" if res_table.y_pred_class[i] == 0 else \"none\"\n",
    "        elif not pred_hm_only and hm_type == \"gc\":\n",
    "            invert_hm = \"none\"\n",
    "        elif pred_hm_only and hm_type == \"oc\":\n",
    "            invert_hm = \"pred_class\"\n",
    "        elif not pred_hm_only and hm_type == \"oc\":\n",
    "            invert_hm = \"never\"\n",
    "\n",
    "        if hm_type == \"gc\":\n",
    "            heatmap, resized_img, max_hm_slice, hm_mean_std = gc.multi_models_grad_cam_3d(\n",
    "                img = res_images[i:i+1], \n",
    "                model_names = res_model_names[i],\n",
    "                cnn = model_3d,\n",
    "                layers = vis_layers[-1],\n",
    "                model_mode = model_mode,\n",
    "                pred_index = pred_idx,\n",
    "                invert_hm = invert_hm,\n",
    "                gcpp_hm = gcpp_hm)\n",
    "        elif hm_type == \"oc\":\n",
    "            heatmap, resized_img, max_hm_slice, hm_mean_std =  utils.volume_occlusion_tabular(\n",
    "                volume = res_images[i:i+1], \n",
    "                tabular_df = tabular_df,\n",
    "                model_names = res_model_names[i],\n",
    "                res_tab = res_table[i:i+1].reset_index(drop = True),\n",
    "                occlusion_size = np.array(occ_size), \n",
    "                occlusion_stride = occ_stride,\n",
    "                both_directions = both_directions,\n",
    "                invert_hm = invert_hm)\n",
    "            \n",
    "        heatmaps_lc.append(heatmap)\n",
    "        max_hm_slices_lc.append(max_hm_slice)\n",
    "        hm_mean_stds_lc.append(hm_mean_std)\n",
    "\n",
    "        if not last_layer_only and hm_type == \"gc\":\n",
    "            heatmap, resized_img, max_hm_slice, hm_mean_std = gc.multi_models_grad_cam_3d(\n",
    "            img = res_images[i:i+1], \n",
    "            cnn = model_3d,\n",
    "            model_names = res_model_names[i],\n",
    "            layers = vis_layers,\n",
    "            model_mode = model_mode,\n",
    "            pred_index = pred_idx,\n",
    "            invert_hm = invert_hm,\n",
    "            gcpp_hm = gcpp_hm)\n",
    "\n",
    "            heatmaps_ac.append(heatmap)\n",
    "            max_hm_slices_ac.append(max_hm_slice)\n",
    "            hm_mean_stds_ac.append(hm_mean_std)\n",
    "\n",
    "        resized_imgs.append(resized_img)\n",
    "        \n",
    "        gci.collect()        \n",
    "        \n",
    "else:\n",
    "    res_table = pd.read_csv(DATA_OUTPUT_DIR + \"all_tab_results_hm_unc_\" + pic_save_name + \".csv\",  sep = \",\")\n",
    "    heatmaps_lc = np.load(DATA_OUTPUT_DIR + \"all_heatmaps_\" + pic_save_name + \".npy\")\n",
    "    max_hm_slices_lc = np.load(DATA_OUTPUT_DIR + \"all_max_activation_indices_\" + pic_save_name + \".npy\")\n",
    "    if not last_layer_only and hm_type == \"gc\":\n",
    "        heatmaps_ac = np.load(DATA_OUTPUT_DIR + \"all_heatmaps_average_conv_layer_\" + pic_save_name + \".npy\")\n",
    "        max_hm_slices_ac = np.load(DATA_OUTPUT_DIR + \"all_max_activation_indices_laverage_conv_layer_\" + pic_save_name + \".npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_heatmap_and_save:   \n",
    "    res_table[\"heatmap_std_last_layer\"] = hm_mean_stds_lc\n",
    "    res_table[\"heatmap_unc_last_layer\"] = (res_table[\"heatmap_std_last_layer\"] - res_table.heatmap_std_last_layer.min()) / (\n",
    "        res_table.heatmap_std_last_layer.max() - res_table.heatmap_std_last_layer.min())\n",
    "    \n",
    "    if not last_layer_only:\n",
    "        res_table[\"heatmap_std_avg_layer\"] = hm_mean_stds_ac\n",
    "        res_table[\"heatmap_unc_avg_layer\"] = (res_table[\"heatmap_std_avg_layer\"] - res_table.heatmap_std_avg_layer.min()) / (\n",
    "            res_table.heatmap_std_avg_layer.max() - res_table.heatmap_std_avg_layer.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics\n",
    "\n",
    "Calculate heatmap uncertainty. Which is the normalized (min-max) averaged standard deviation over each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not last_layer_only and hm_type == \"gc\":\n",
    "    print(np.corrcoef(res_table[\"heatmap_unc_avg_layer\"], res_table[\"heatmap_unc_last_layer\"]))\n",
    "    print(np.corrcoef(res_table[\"y_pred_unc\"], res_table[\"heatmap_unc_avg_layer\"]))\n",
    "print(np.corrcoef(res_table[\"y_pred_unc\"], res_table[\"heatmap_unc_last_layer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not last_layer_only and hm_type == \"gc\":\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (15, 5))\n",
    "else:\n",
    "    fig, (ax1, ax3) = plt.subplots(1,2, figsize = (10, 5))\n",
    "\n",
    "sns.boxplot(x = \"unfavorable\",\n",
    "    y = \"y_pred_unc\",\n",
    "    data = res_table,\n",
    "    ax = ax1)\n",
    "sns.stripplot(x = \"unfavorable\",\n",
    "    y = \"y_pred_unc\",\n",
    "    hue = 'y_pred_class',\n",
    "    alpha = 0.75,\n",
    "    palette=[\"C2\", \"C3\"],\n",
    "    data = res_table,\n",
    "    ax = ax1)\n",
    "ax1.legend(title='predicted class', loc='upper center')\n",
    "ax1.set(xlabel='true class', ylabel='prediction uncertainty')\n",
    "\n",
    "if not last_layer_only:\n",
    "    sns.boxplot(x = \"unfavorable\",\n",
    "        y = \"heatmap_unc_avg_layer\",\n",
    "        data = res_table,\n",
    "        ax = ax2)\n",
    "    sns.stripplot(x = \"unfavorable\",\n",
    "        y = \"heatmap_unc_avg_layer\",\n",
    "        hue = 'y_pred_class',\n",
    "        alpha = 0.75,\n",
    "        palette=[\"C2\", \"C3\"],\n",
    "        data = res_table,\n",
    "        ax = ax2)\n",
    "    ax2.legend(title='predicted class', loc='upper center')\n",
    "    ax2.set(xlabel='true class', ylabel='heatmap uncertainty avg layer')\n",
    "\n",
    "sns.boxplot(x = \"unfavorable\",\n",
    "    y = \"heatmap_unc_last_layer\",\n",
    "    data = res_table,\n",
    "    ax = ax3)\n",
    "sns.stripplot(x = \"unfavorable\",\n",
    "    y = \"heatmap_unc_last_layer\",\n",
    "    hue = 'y_pred_class',\n",
    "    alpha = 0.75,\n",
    "    palette=[\"C2\", \"C3\"],\n",
    "    data = res_table,\n",
    "    ax = ax3)\n",
    "ax3.legend(title='predicted class', loc='upper center')\n",
    "ax3.set(xlabel='true class', ylabel='heatmap uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "           x = \"heatmap_unc_last_layer\",\n",
    "           y = \"y_pred_unc\",\n",
    "            data = res_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Heatmaps, Images and updated Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_heatmap_and_save:\n",
    "    res_table.to_csv(DATA_OUTPUT_DIR + \"all_tab_results_hm_unc_\" + pic_save_name + \".csv\",  index=False)\n",
    "    np.save(DATA_OUTPUT_DIR + \"all_heatmaps_\" + pic_save_name + \".npy\", heatmaps_lc)\n",
    "    np.save(DATA_OUTPUT_DIR + \"all_max_activation_indices_\" + pic_save_name + \".npy\", max_hm_slices_lc)\n",
    "    \n",
    "    if not last_layer_only and hm_type == \"gc\":\n",
    "        np.save(DATA_OUTPUT_DIR + \"all_heatmaps_average_conv_layer_\" + pic_save_name + \".npy\", heatmaps_ac)\n",
    "        np.save(DATA_OUTPUT_DIR + \"all_max_activation_indices_laverage_conv_layer_\" + pic_save_name + \".npy\", max_hm_slices_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Average Heatmaps\n",
    "\n",
    "Plot the average heatmaps for all patients. Once for class 0, once for class 1 and once for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(res_table[\"y_pred_class\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hm_lc = np.array(np.take(heatmaps_lc, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "if not last_layer_only:\n",
    "    mean_hm_ac = np.array(np.take(heatmaps_ac, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "mean_image = np.array(np.take(res_images, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "\n",
    "phm.plot_heatmap(mean_image, mean_hm_lc,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap = cmap,\n",
    "            hm_positive = hm_positive)\n",
    "if not last_layer_only:\n",
    "    phm.plot_heatmap(mean_image, mean_hm_ac,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(res_table[\"y_pred_class\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hm_lc = np.array(np.take(heatmaps_lc, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "if not last_layer_only:\n",
    "    mean_hm_ac = np.array(np.take(heatmaps_ac, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "mean_image = np.array(np.take(res_images, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "\n",
    "phm.plot_heatmap(mean_image, mean_hm_lc,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap = cmap,\n",
    "            hm_positive = hm_positive)\n",
    "if not last_layer_only:\n",
    "    phm.plot_heatmap(mean_image, mean_hm_ac,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(0,407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hm_lc = np.array(np.take(heatmaps_lc, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "if not last_layer_only:\n",
    "    mean_hm_ac = np.array(np.take(heatmaps_ac, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "mean_image = np.array(np.take(res_images, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "\n",
    "phm.plot_heatmap(mean_image, mean_hm_lc,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap = cmap,\n",
    "            hm_positive = hm_positive)\n",
    "if not last_layer_only:\n",
    "    phm.plot_heatmap(mean_image, mean_hm_ac,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Plots as PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from importlib import reload\n",
    "#reload(phm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if generate_pictures:\n",
    "    if not last_layer_only:\n",
    "        phm.plot_gradcams_last_avg_org(\n",
    "            res_table = res_table, \n",
    "            vis_layers = vis_layers,\n",
    "            res_images = res_images,\n",
    "            res_model_names = res_model_names,\n",
    "            model_3d = model_3d,\n",
    "            layer_mode = \"mean\", \n",
    "            heatmap_mode = \"avg\", \n",
    "            save_path = PIC_OUTPUT_DIR, \n",
    "            save_name = pic_save_name, save = True)\n",
    "\n",
    "        phm.plot_gradcams_last_avg_org(\n",
    "            res_table = res_table, \n",
    "            vis_layers = vis_layers,\n",
    "            res_images = res_images,\n",
    "            res_model_names = res_model_names,\n",
    "            model_3d = model_3d,\n",
    "            layer_mode = \"mean\",\n",
    "            heatmap_mode = \"max\", \n",
    "            save_path = PIC_OUTPUT_DIR, \n",
    "            save_name = pic_save_name, save = True)\n",
    "    else:\n",
    "        phm.plot_heatmaps_avg_max_org(\n",
    "            pat_data = pat_dat,\n",
    "            res_table = res_table, \n",
    "            res_images = res_images,\n",
    "            heatmaps = heatmaps_lc,\n",
    "            cmap = cmap,\n",
    "            hm_positive = hm_positive,\n",
    "            save_path = PIC_OUTPUT_DIR, \n",
    "            save_name = pic_save_name, save = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Plots to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_wrong_out = False # should already be defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not only_wrong_out: # all ids\n",
    "    pat_ids = list(res_table[\"p_id\"])\n",
    "else: # only ids with low uncertainty and wrong classified\n",
    "    pat_ids = list(res_table.query(\"pred_correct == False and y_pred_unc < 0.2\").p_id)\n",
    "    res_table[res_table.p_id.isin(pat_ids)].to_csv(\n",
    "        DATA_OUTPUT_DIR + \"all_tab_results_hm_unc_\" + pic_save_name + \"_wrong_cl.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_table[res_table.p_id.isin(pat_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "from tqdm import tqdm\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(0)\n",
    "\n",
    "# imagelist is the list with all image filenames\n",
    "for patient in tqdm(pat_ids):\n",
    "    \n",
    "    name_start = PIC_OUTPUT_DIR + \"pat\" + str(patient) + \"_\" + pic_save_name\n",
    "    \n",
    "    if not last_layer_only:\n",
    "        pdf.add_page(orientation=\"L\")  # Use default page size (A4) in landscape mode\n",
    "        pdf.set_left_margin(10)\n",
    "        pdf.set_right_margin(10)\n",
    "        x, y, w, h = (0, 10, 190, 190)\n",
    "        pdf.image(name_start + \"_last_and_all_layers_avg.png\", x, y, w, h)\n",
    "        x, y, w, h = (140, 10, 190, 190)\n",
    "        pdf.image(name_start + \"_last_and_all_layers_max.png\", x, y, w, h)\n",
    "    else:\n",
    "        pdf.add_page(orientation=\"P\")  # Use default page size (A4) in portrait mode\n",
    "        pdf.set_left_margin(10)\n",
    "        pdf.set_right_margin(10)\n",
    "        x, y, w, h = (0, 10, 205, 205)\n",
    "        pdf.image(name_start + \"_last_layer_avg_max_orig.png\", x, y, w, h)\n",
    "\n",
    "if only_wrong_out:\n",
    "    pdf.output(PIC_OUTPUT_DIR + \"10Fold_ensembling\" + pic_save_name[6:] + \"_all_patients_wrong_cl.pdf\", \"F\")\n",
    "else:\n",
    "    pdf.output(PIC_OUTPUT_DIR + \"10Fold_ensembling\" + pic_save_name[6:] + \"_all_patients.pdf\", \"F\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
